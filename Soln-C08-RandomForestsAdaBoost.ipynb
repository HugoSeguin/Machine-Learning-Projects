{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DS 301: Applied Data Modeling and Predictive Analysis**\n",
    "\n",
    "# Lab 8 – Random Forests, AdaBoost\n",
    "\n",
    "Nok Wongpiromsarn, 10 August 2022\n",
    "\n",
    "**Instructions:**\n",
    "Perform regression with 'SalePrice' as the output.\n",
    "1. Select at least 2 features of your choice. Explain why you select these features.\n",
    "2. Prepare the data using Pipeline and ColumnTransformer. Explain the reasoning behind having each transformation in the Pipeline. Hint: Consider, e.g., StandardScaler, OneHotEncoder, etc.\n",
    "3. Train the following models\n",
    "   - RandomForestRegressor\n",
    "   - AdaBoostRegressor\n",
    "   - XGBRegressor\n",
    "4. Evaluate each of the above models based on RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get the data and allocate some for testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"datasets/house-price.csv\")\n",
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Select at least 2 features of your choice. Explain why you select these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice           1.000000\n",
       "OverallQual         0.785555\n",
       "GrLivArea           0.695652\n",
       "GarageCars          0.640991\n",
       "GarageArea          0.624139\n",
       "                      ...   \n",
       "Foundation_Stone    0.002416\n",
       "Fence_GdPrv         0.002171\n",
       "Condition1_RRNe     0.002107\n",
       "GarageCond_Gd       0.001725\n",
       "RoofMatl_Metal      0.000546\n",
       "Name: SalePrice, Length: 288, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll only use the training set to not contaminate the test set\n",
    "\n",
    "data_encoded = pd.get_dummies(data_train)\n",
    "abs_corr = abs(data_encoded.corr()[\"SalePrice\"])\n",
    "abs_corr.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath',\n",
       "       'GarageCars', 'GarageArea', 'ExterQual_TA'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pick the features with correlation > 0.55\n",
    "# Essentially, we want to pick features with high correlation.\n",
    "\n",
    "attribs_encoded = data_encoded.columns[abs_corr > 0.55]\n",
    "attribs_encoded = attribs_encoded[(attribs_encoded != \"SalePrice\")]\n",
    "attribs_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 8 atrributes\n",
      "  Column          Dtype      Null Count\n",
      "  ------          -----      ----------\n",
      "  OverallQual     int64          0     \n",
      "  TotalBsmtSF     int64          0     \n",
      "  1stFlrSF        int64          0     \n",
      "  GrLivArea       int64          0     \n",
      "  FullBath        int64          0     \n",
      "  GarageCars      int64          0     \n",
      "  GarageArea      int64          0     \n",
      "  ExterQual       object         0     \n"
     ]
    }
   ],
   "source": [
    "# Convert attribs_encoded to the original attributes before one-hot encoding.\n",
    "# Note that the following code assumes that the encoded attribute name is obtained from the original attribute name\n",
    "# by appending \"_\" and that the original attribute names do not include \"_\"\n",
    "\n",
    "attribs = []\n",
    "\n",
    "for a in attribs_encoded:\n",
    "    index = a.find('_')\n",
    "    if index > 0:\n",
    "        a = a[:index]\n",
    "    if a not in attribs:\n",
    "        attribs.append(a)\n",
    "        \n",
    "# Print selected attributes and their corresponding types\n",
    "print(\"Selected {} atrributes\".format(len(attribs)))\n",
    "print(\"  {:15} {:10} {:^10}\".format(\"Column\", \"Dtype\", \"Null Count\"))\n",
    "print(\"  {:15} {:10} {:^10}\".format(\"------\", \"-----\", \"----------\"))\n",
    "for attr in attribs:\n",
    "    print(\"  {:15} {:10} {:^10}\".format(attr, str(data_train[attr].dtype), data_train[attr].isnull().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare the data using Pipeline and ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OverallQual', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars', 'GarageArea']\n",
      "['ExterQual']\n"
     ]
    }
   ],
   "source": [
    "# Separate the selected features based on their types\n",
    "\n",
    "num_attribs = [a for a in attribs if data[a].dtypes == 'int64']\n",
    "cat_attribs = [a for a in attribs if data[a].dtypes == 'object']\n",
    "\n",
    "# Ensure that we've covered all the selected features\n",
    "assert len(num_attribs) + len(cat_attribs) == len(attribs)\n",
    "\n",
    "print(num_attribs)\n",
    "print(cat_attribs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# We need to scale the features and convert categorical features to numerical ones.\n",
    "# There is no missing values in this case, so there is really no need to use SimpleImputer.\n",
    "# I'll still add SimpleImputer to illustrate how you may use Pipeline, together with ColumnTransformer\n",
    "# to create a complete transformer.\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_attribs), # Apply StandardScaler to numerical features\n",
    "    ('cat', cat_transformer, cat_attribs),  # Apply cat_transformer to categorical features\n",
    "])\n",
    "\n",
    "X_train = preprocessor.fit_transform(data_train[attribs])\n",
    "y_train = data_train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the following models\n",
    "\n",
    "- RandomForestRegressor\n",
    "- AdaBoostRegressor\n",
    "- XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "             n_jobs=-1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100,\n",
       "             n_jobs=-1, num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100,\n",
       "             n_jobs=-1, num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, ...)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg_rnd = RandomForestRegressor(n_estimators=100, criterion='squared_error', n_jobs=-1)\n",
    "reg_rnd.fit(X_train, y_train)\n",
    "\n",
    "reg_adb = AdaBoostRegressor(DecisionTreeRegressor(max_depth=3), n_estimators=100, loss=\"square\", random_state=4)\n",
    "reg_adb.fit(X_train, y_train)\n",
    "\n",
    "reg_xgb = XGBRegressor(n_estimators=100, n_jobs=-1)\n",
    "reg_xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate each of the above models based on RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to transform the test data in the same way that we transform the training data\n",
    "X_test = preprocessor.transform(data_test[attribs])\n",
    "y_test = data_test['SalePrice']\n",
    "\n",
    "# Make prediction on the test set\n",
    "y_pred_rnd = reg_rnd.predict(X_test)\n",
    "y_pred_adb = reg_adb.predict(X_test)\n",
    "y_pred_xgb = reg_xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE RandomForestRegressor: 30889.08408687132\n",
      "RMSE AdaBoostRegressor: 37735.3069269716\n",
      "RMSE XGBRegressor: 30840.253489670064\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "rmse_rnd = sqrt(mean_squared_error(y_test, y_pred_rnd))\n",
    "print(\"RMSE RandomForestRegressor: {}\".format(rmse_rnd))\n",
    "\n",
    "rmse_adb = sqrt(mean_squared_error(y_test, y_pred_adb))\n",
    "print(\"RMSE AdaBoostRegressor: {}\".format(rmse_adb))\n",
    "\n",
    "rmse_xgb = sqrt(mean_squared_error(y_test, y_pred_xgb))\n",
    "print(\"RMSE XGBRegressor: {}\".format(rmse_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
